This time, there is again much less information given from me, and much more for you to figure out, similarly to last time. Most of the tasks do not have one solution, you can approach them from a different perspectives, and I will just give you some feedback.

This week, we will continue developing our API-testing project. Ideally, continue working on the same code-base, and extract it to a dedicated project (from the original homework one), if you already haven't done so.

Generally, please make sure (now and also for the homework from last week) that:

All your classes are in a namespace.
You use Composer to auto-load all classes (require vendor/autoload only at the very beginning of the top-level program).
[Optional]: You can of course use any third party libraries you find, as long as you install them via Composer. At least Monolog, the logging library, is handy to print any kind of messages, and very easy to use.
###Enhancing TestChecks First part, as a warm-up, create several more TestChecks, following the same concept as last week. You can create a class to check anything from the API response. It does not have to be a check which will pass for all requests. For instance a class which will test whether a CarPhone product is present in the contracts part of the response seems quite topical. If you cannot come up with anything, just think about what you usually test: Is there an URL rewrite included in the link? Are there enough deals? Are they ordered by price? You can even create a "parametrized" class, for instance a CurrencyGroupCheck, which will be instantiated with an array of currencies, and it will check whether the deals with these currencies have been present, in the right order.

We need to ensure every TestCheck will be able to say whether it succeeded or failed. Create a custom TestStepFailExceptin class, and throw an exception of that class if the test check fails. If the exception is not thrown, the check is assumed to pass.

###TestStep Recall how TestInput and TestChecks are supposed to work. All TestChecks are probably extending your AbstractCheck class. Create a new class TestStep, which wraps these two together (it should be quite a small class, just a container to easily handle these two together). Essentially, TestStep is one testing unit we can mark as pass/fail. In Behat, it is represented by one line in the scenario (which combines what to do and what to check together, if you think about it).

###TestGenerator Last time, we loaded the tests from a CSV. It is good, but we need to specify every combination of testing parameters, which would lead to repetition. In this part, you will create a class which will essentially generate TestSteps. We will generate various TestInputs from the "atomic" parameters, and attach any relevant TestChecks to them.

The first part is generating the inputs. Let's say we have 10 article IDs, 3 territories, 2 site codes and 3 widgets. If we want to test all combinations, it combines up to 90! If you use nested loops, it is quite easy to generate all these combinations beforehand.

More importantly, we want to combine specific TestInputs with relevant TestChecks. We can probably add the "generic" checks to every input (at least WidgetTitleCheck and TwoListsOfProductsCheck, as we designed them last week). In addition, we might want to say, that for instance for two specific article IDs representing phone articles, we want to also add for example ContractsIncludedCheck, CarPhonePresentCheck. Or, a different example, we might add a parametrized ProductNumberCheck, which tests whether there is a certain number of products in the response. We want to specify this number differently for the review widget (it's 4 deals only), and differently for CC (there are up to 100, so we can test whether there are at least 20, let's say).

We have already calculated that various combinations of "atomic" input parameters give us let's say 90 inputs. The TestGenerator should be able to produce these and combine them with the checks, producing even bigger number of complete TestSteps. In other words, you add 1 or more checks for every input. If you added 5 checks for one input (in average), that gives us 450 TestSteps. It's important to keep in mind each TestStep is self-contained, it consists of only one individual input and one check. If we check for more than one thing, we should create more steps, because one might pass and another one fail.

###TestPlan The last thing for you to build this week is TestPlan class. Basically, it should replace any top-level script you would use otherwise. It's generally a good practice to put as much code as possible into classes. Our TestPlan object can use TestInputSource from last week or/and TestGenerator to create list of TestSteps. You can try both approaches, and you can create two slightly different TestPlans if you need - don't forget about the inheritance!

The TestPlan should be responsible for obtaining the list of TestSteps from the source/generator, running them in a loop, plus printing the results (as a simple messages)). Make sure you use the catch block to check whether TestStepFailExceptin from any check was thrown. You can choose whether the test plan will continue after a fail, or whether it will immediately interrupt the execution (I believe Behat has such option you use, am I right?).